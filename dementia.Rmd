---
title: "Dementia"
author: "Examination Number: Y3866839"
date: "30/11/2020"
output: 
  bookdown::html_document2: default
bibliography: references/references.bib
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE,
                      warning = FALSE,
                      message = FALSE,
                      fig.retina = 3)

library(tidyverse)
library(magrittr)
library(dplyr)
library(knitr)
library(readxl)
library(caret)
library(GGally)
library(ROCR)

```

## Introduction{-}
Clinical visit data was collected from 150 subjects aged between 60 and 96. Data collected included the subjects age, gender, years of education and socioeconomic status (assessed by the Hollingshead Index of Social Position). Each subject underwent MRIs on at least two separate visits (over one year apart) in order to assess estimated intracranial volume and normalised whole brain volume. They were also given a score at each visit for the Mini-Mental State Examination (MMSE), that is used in clinical practice to measure cognitive impairment, and were given a Clinical Dementia Rating. 

The Clinical Dementia Rating (CDR) is a global rating device, first introduced in 1982. It is calculated on the basis of testing six cognitive and behavioural domains such as memory, orientation, judgment, problem solving, community affairs, home and hobbies and personal care. It is based on a five point scale of 0-3; 0 = no dementia, 0.5 = questionable dementia, 1 = mild cognitive impairment/ mild dementia, 2 = moderate cognitive impairment/ moderate dementia and 3 = severe cognitive impairment/ severe dementia [@Morris1997].

The analysis performed here will combine the patient and clinical visit data and tidy this into a format suitable for analysis. Then I aim to determine whether Clinical Dementia Rating can be predicted based on a number factors which are associated with increased risk of dementia such as age and socioeconomic status (**REF**) and factors associated with dementia progression such as intracranial volume (**REF**) and MMSE score. This assessment will be performed using supervised methods of machine learning. I will also assess which machine learning method is able to most accurately predict CDR. 

Analysis was conducted in R [@Rbase] using Rmarkdown [@Allaire2020; @Xie2018; @Xie2020]

## Data Import{-}
```{r data import}
#Read in the patient data and the visit data as two separate .txt files 

patient <- read_excel("data_raw/patient_data.xlsx")

visit <- read_excel("data_raw/visit_data.xlsx")
```

Clinical visit data and patient data were stored in two separate Excel spreadsheets. The two spread sheets, which were read into R separately. This was also necessary as the visit data and patient data had different numbers of observations. There were 150 participants in the study (hence 150 observations for patient data) however each patient had multiple MRI scans on separate visits, so there are 373 observations in the visit data. 

<!-- do I need to show the two data sets str for a visual representation of this? -->
```{r visit and patient structure, include = TRUE}

str(patient)
str(visit)
```

## Data Tidying{-}

The column names in both dataframes are not in a tidy format. **show this here?** Using the `names()` function, the column names can be replaced by tidier names in snake_case. 

```{r data tidy column headings, include = FALSE}

#Change the headings in patient data to a tidy format
#look at existing column names
colnames(patient)

#create and assign new column names
colnames_patient <- c("subject_ID", "group", "sex", "years_of_education", "socioeconomic_status")
names(patient) <- colnames_patient

#Change headings in the visit data to more meaningful names and to a tidy format
#look at existing column names
colnames(visit)

#create and assign new column names
colnames_visit <- c("subject_ID", "MRI_number", "visit", "age", "MMSE_score", "CDR", "intracranial_volume", "whole_brain_volume", "atlas_scaling_factor")
names(visit) <- colnames_visit
```

The visit and patient data were read in as two separate files as they have different amounts of variables. There are a number of different functions which can be used to join two dataframes ("x" and "y") together by a specified join column, which is present in both dataframes. The `inner_join()` function produces a combination dataframe of the two dataframes provided to it based on a specified column. In this case the chosen join column was subject_ID we want to combine all the information **for each visit of each subject** in to one row. The `inner_join()` function creates a dataframe which retains all the rows from dataframes x and y, therefore enables you to join two dataframes with different numbers of observations. If one dataframe (x) has less rows than the other (y) the rows in x will be duplicated based on the observations in the join column. In this case, patient data rows are duplicated for every set of visit data from that patient. Other functions such as `left_join()` and `right_join()` will only keep the rows from either x or y and any extra rows will be deleted. These functions were not used here as it is important to maintain all the visit data.  

```{r innerjoin, include = FALSE}
#Join the patient data and visit data tables together using inner join. this function compared to others enables you to duplicate the patient data rows to joing together based on subject id. You can multiply the patient data so same no obs.
dementia <- inner_join(patient, visit, by = "subject_ID", copy = FALSE, suffix = c(".x", ".y"))
```

The IDs of the subjects in this dataframe are in a format used in the clinic. This format is unnecessary for this analysis and could overcomplicate any summary statistics and visual representations of the data. The subject IDs can be tidied by removing the "OAS2_0" in order to leave a simple three digit number. `str_replace()` is used to replace matched patterns in a string of characters, so can be used to replace "OAS2_0" with nothing (""). Due to the large number of observations, `str_replace()` is first applied a single observation to check whether the function peforms the necessary task correctly. The function can then be applied to all the observations in the column using the `mutate()` function. 

```{r subject IDs, include = FALSE}

#Extract one observation/subject ID to work with 
one_subject_ID <- dementia$subject_ID[1]

one_subject_ID

one_subject_ID %>% 
  str_replace("OAS2_0", "")

#Apply to the whole column
dementia_tidy <- dementia %>% 
  mutate(subject_ID = subject_ID %>% 
           str_replace("OAS2_0", ""))
```

From a quick scan of the data upon import it is clear that there are a number of NA values. NA values within dataframes are detected using the `is.na()` function. The output of this function is a list of every row and a TRUE/FALSE indicator of NA values. Unfortunately this function has a max print limit and due to the large size of this dataset, 297 rows are omited from the output. It is for this reason that the `any(is.na())` and `which(is.na())` functions are used. `any(is.na())` provides a simple output of TRUE or FALSE based on whether or not missing values are present within the dataframe. `which(is.na())` determines what positions in the dataframe the NA values are; the output of which can be seen below. From this, one is able to see that there are 21 missing values within the dataframe. 

```{r NA values, include = TRUE}
which(is.na(dementia_tidy))
```

When the `str()` function is applied to the patient data, it is clear that a number of the NA values are in the socioeconomic status column. It can be determined using `which(is.na(dementia$socioeconomic_status))` that there are 19 NA values within this column. It is unclear where the other NA values are. `na.omit()` is used to remove any rows with missing values. It is important to remove any missing values in order to not interfere with the analysis. Other functions exist that can predict what the NA values would be and replace them in the dataframe but this is not possible here as socioeconomic status is an independent variable here and cannot be predicted from the data we have. 

```{r removing NAs, include = FALSE}
#Several subjects do not have a score for socioeconomic status. As I am doing machine learning and want to determine whether we can predict CDR from the different variables I need each variable to have a value for every subject. 
#Hence need to remove NAs

#Determine if there are any NA values
any(is.na(dementia_tidy))
#Output is true - this shows me that somewhere in the dataframe there are NA values. 
which(is.na(dementia_tidy))
#This shows me that there are 21 observations that have an NA value for one of the variables
#From a quick scan through the dataset I suspect that the missing values are in the socioeconomic status column. 
which(is.na(dementia_tidy$socioeconomic_status))
#I can see that 19 of the NAs are in the socioeconomic status column. 
#The other two were found to be in MMSE score
which(is.na(dementia_tidy$MMSE_score))

#We want to remove all the observations which contain an NA value for one or more variables
dementia_no_na <- na.omit(dementia_tidy)

which(is.na(dementia_no_na))
#Proves that there are no more NA values in the dataset
```

## Data summary{-}

<!-- generate some kind of summary stats!! Maybe plots of the data? -->

## Linear Discriminant Analysis{-}

Linear Discriminant Analysis can 

```{r LDA, include = FALSE}
#Create a vector of row numbers to split the dataset into training and testing sets
ids <- createDataPartition(y = dementia_no_na$CDR,
                           p = 0.75, 
                           list = FALSE)

#use dlpyr function to slice rows based on their index and create the two data sets
train <- dementia_no_na %>% slice(ids)
test <- dementia_no_na %>% slice(-ids)

#Train the model
lda <- train %>% 
  select(years_of_education,
         socioeconomic_status,
         age,
         MMSE_score,
         intracranial_volume,
         whole_brain_volume, 
         atlas_scaling_factor) %>% 
  MASS::lda(grouping = train$CDR)

#Predict on the training data
plda_train <- train %>% 
  select(years_of_education,
         socioeconomic_status,
         age,
         MMSE_score,
         intracranial_volume,
         whole_brain_volume, 
         atlas_scaling_factor) %>% 
  predict(object = lda)

#examine the confusion matrix...
confusionMatrix(plda_train$class,
                factor(train$CDR))

#Accuracy is only 72.56%. Can be 95% certain that this lies between 66.77% and 77.83%. This is significantly better than by predicting the most common class. 

#Predict classes of test data based on LDA model
plda_test <- test %>% 
  select(years_of_education,
         socioeconomic_status,
         age,
         MMSE_score,
         intracranial_volume,
         whole_brain_volume, 
         atlas_scaling_factor) %>% 
  predict(object = lda)

#Examine the confusion matrix
confusionMatrix(plda_test$class,
                factor(test$CDR))

##HELP!!!!!!!!
#Accuracy is 77.27%. 95% confidence that it is between 67.11% and 85.53%. This again, is significantly better than simply predicting the most common class. 

#TO PLOT...

#Extract scores from training set 
lda_labelled_train <- data.frame(plda_train$x,
                                  CDR = train$CDR)
#extract the scores from test set
lda_labelled_test <- data.frame(plda_test$x,
                                CDR = test$CDR)
```

```{r LDA-train, fig.cap="plot of LDA training set"}

source("scripts/theme_stella.R")

lda_labelled_train %>% 
  ggplot(aes(x = LD1, y = LD2, color = factor(CDR))) +
  geom_point() +
  theme_stella()

#There is a fair bit of overlap between the different CDRs here. 
```

```{r LDA-test, fig.cap="plot of LDA test set"}

lda_labelled_test %>% 
  ggplot(aes(x = LD1, y = LD2, color = factor(CDR))) +
  geom_point() +
  theme_stella()

#separates out a bit better. 
```

```{r LDA-both, fig.cap="plot of LDA train and test sets"}

lda_labelled <- rbind(lda_labelled_test, lda_labelled_train)

lda_labelled %>% 
  ggplot(aes(x = LD1, y = LD2, colour = factor(CDR))) +
  geom_point() +
  theme_stella()

#not very clear distinction, especially at lower CDRs. 

```

## Random Forest{-}
Random Forests is a machine learning method for classification and regression. They operate by constructing a large number of decision trees from different subsets of the training dataset.  The decision trees are then used to output the class that is the mode of the classes output by each of the individual trees. Random forest overcomes the common problem of overfitting which is encountered with Decision Tree methods. Random Forest is also well suited to a smaller sample size.  

```{r Random Forest, include = FALSE}
#Set random seed to make results reproducible
set.seed(17)

#calculate the size of each of the datasets
data_set_size <- floor(nrow(dementia_no_na)/2)

#generate a random sample of "data_set_size" indexes
indexes <- sample(1:nrow(dementia_no_na), size = data_set_size)

#Assign the data to the corrext sets
training <- dementia_no_na[indexes,]
validation1 <- dementia_no_na[-indexes, ]

#Make dependent variable a factor, in order for random forest to do classification not regression
dementia_no_na$CDR <- factor(dementia_no_na$CDR)

#Peform the training
rf <- randomForest::randomForest(formula = CDR~., data = dementia_no_na, ntree = 500, mtry = 3, importance = TRUE)

rf

#write about why you have to randomForest:: because librarying the random forest package overrules some of the functions you need from other packages - check which!! - see listendata ref
#write about less mtry = reduces correlation and strentgh and increasing it increases both. there is an optimal mtry range. starts with mtry of 3 - sqrt of predictors

#find the optimal mtry value with the minimum out of bag(OOB) error

mtry <- randomForest::tuneRF(dementia_no_na[-1], 
               dementia_no_na$CDR,
               ntreeTry = 500,
               stepFactor = 1.5,
               improve = 0.01,
               trace = TRUE, 
               plot = TRUE)
best_m <- mtry[mtry[,2] == min(mtry[,2]), 1]

mtry
best_m

#4 or 6 are the best mtry values

#Use best mtry value
set.seed(17)

rf <- randomForest::randomForest(formula = CDR~., 
                                 data = dementia_no_na, 
                                 ntree = 500, 
                                 mtry = best_m, 
                                 importance = TRUE)

print(rf)

#OOB estimate of error rate = 12.43%

#Evaluate the variable importance
randomForest::importance(rf)
randomForest::varImpPlot(rf)

#Higher mean decrease accuracy or mean decrease gini score, the higher the importance of this variable in the model. 
#Here group is highest - need to exclude this. Then MMSE_score is a good predictor of CDR, followed by age, whole brain volume etc etc. Years of education, sex and socioeconomic status have little impact on CDR.  

#Use classifie to see what happens when we use classified to predict classes for validation set
prediction_for_table <- predict(rf, validation1[,5])
```
**NOT WORKING YET LOLS**


## Conclusion{-}

**WHY IS THIS NOT WORKING AAAAAA**
```{r wordcount}

install_github("benmarwick/wordcountaddin")

wordcount <- wordcountaddin::word_count("dementia.Rmd")
wordcount
#current wordcount is ??
```
**Wordcount:** `r wordcount`

## References{-}
